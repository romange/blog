<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>These are the wrong sort of bees</title><link>https://romange.github.io/blog/preview/</link><description>Recent content on These are the wrong sort of bees</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 23 Oct 2022 09:24:23 +0300</lastBuildDate><atom:link href="https://romange.github.io/blog/preview/index.xml" rel="self" type="application/rss+xml"/><item><title>balanced vs unbalanced</title><link>https://romange.github.io/blog/preview/2022/10/23/balanced-vs-unbalanced/</link><pubDate>Sun, 23 Oct 2022 09:24:23 +0300</pubDate><guid>https://romange.github.io/blog/preview/2022/10/23/balanced-vs-unbalanced/</guid><description>&lt;p>Or why dragonfly is winning the hearts of developers&amp;hellip;&lt;/p></description></item><item><title>Dragonfly Cache Design</title><link>https://romange.github.io/blog/preview/2022/06/23/dragonfly-cache-design/</link><pubDate>Thu, 23 Jun 2022 12:00:00 +0300</pubDate><guid>https://romange.github.io/blog/preview/2022/06/23/dragonfly-cache-design/</guid><description>&lt;p>I talked in my &lt;a href="https://romange.github.io/blog/preview/2022/01/30/redis-analysis-part-2-simplicity/">previous post&lt;/a> about Redis eviction policies.
In this post, I would like to describe the design behind Dragonfly cache.&lt;/p></description></item><item><title>Redis Analysis - Part 2: Simplicity</title><link>https://romange.github.io/blog/preview/2022/01/30/redis-analysis-part-2-simplicity/</link><pubDate>Sun, 30 Jan 2022 20:00:00 +0200</pubDate><guid>https://romange.github.io/blog/preview/2022/01/30/redis-analysis-part-2-simplicity/</guid><description>&lt;p>Let&amp;rsquo;s talk about the simplicity of Redis.
Redis was initially designed as a simple store, and it seems that its APIs achieved this goal.
Unfortunately, Redis&amp;rsquo;s simple design makes it unreliable and difficult to manage in production.&lt;/p>
&lt;p>So the question is - what simplicity means to you as a datastore user?&lt;/p></description></item><item><title>Redis Analysis - Part 1: Threading model</title><link>https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/</link><pubDate>Thu, 09 Dec 2021 11:00:00 +0300</pubDate><guid>https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/</guid><description>&lt;p>Following my previous post, we are going start with the &amp;ldquo;hottest potato&amp;rdquo; - single-threaded vs
multi-threaded argument.&lt;/p></description></item><item><title>A prelude to analysis of Redis memory-store</title><link>https://romange.github.io/blog/preview/2021/11/28/a-prelude-to-analysis-of-redis-memory-store/</link><pubDate>Sun, 28 Nov 2021 17:46:19 +0300</pubDate><guid>https://romange.github.io/blog/preview/2021/11/28/a-prelude-to-analysis-of-redis-memory-store/</guid><description>&lt;p>During the last 13 years, Redis has become a truly ubiquitous memory store that has won the hearts
of numerous dev-ops and software engineers. Indeed, according to &lt;a href="https://insights.stackoverflow.com/survey/2021#databases">StackOverflow survey in
2021&lt;/a>, Redis is the most loved database for the 5th time in a row and is at the top of
&lt;a href="https://db-engines.com/en/ranking/key-value+store">db-engines&lt;/a> ranking, way before the next contestant.
But how well does Redis utilizes modern hardware systems?
Will it stay competitive in a few years without reinventing itself?&lt;/p></description></item><item><title>IO_URING powered event-loop with efficient message passing</title><link>https://romange.github.io/blog/preview/2020/09/05/io_uring-powered-event-loop-with-efficient-message-passing/</link><pubDate>Sat, 05 Sep 2020 20:30:11 +0300</pubDate><guid>https://romange.github.io/blog/preview/2020/09/05/io_uring-powered-event-loop-with-efficient-message-passing/</guid><description>&lt;p>IO_URING is the new API that provides an efficient communication channel with the kernel via shared ring-buffer. It has been specially designed for handling all types of Linux I/O requests and it finally unifies file and networking calls into the same API. This article covers an experimental layer in GAIA that allows building an efficient backend server using IO_URING api. This layer shows an order of magnitude better throughput on a single server compared to epoll-based approaches. Also, it demonstrates a flexible inter-thread message passing mechanism specially designed for reactive systems.&lt;/p></description></item><item><title>Gaia Mapreduce Tutorial - part2</title><link>https://romange.github.io/blog/preview/2019/11/01/gaia-mapreduce-tutorial-part2/</link><pubDate>Fri, 01 Nov 2019 10:30:12 +0300</pubDate><guid>https://romange.github.io/blog/preview/2019/11/01/gaia-mapreduce-tutorial-part2/</guid><description>&lt;p>In &lt;a href="https://romange.github.io/blog/preview/2019/07/15/gaia-mapreduce-tutorial-part1/">part 1 of my tutorial&lt;/a> I&amp;rsquo;ve explained behind the scenes of a typical mapreduce
framework. In this section we will go over GAIA-MR and will show why it&amp;rsquo;s more efficiant than other open-source frameworks.&lt;/p></description></item><item><title>Benchmarking GAIA MR on Google cloud</title><link>https://romange.github.io/blog/preview/2019/07/25/benchmarking-gaia-mr-on-google-cloud/</link><pubDate>Thu, 25 Jul 2019 11:38:01 +0300</pubDate><guid>https://romange.github.io/blog/preview/2019/07/25/benchmarking-gaia-mr-on-google-cloud/</guid><description>&lt;p>I&amp;rsquo;ve recently had a chance to benchmark GAIA in Google cloud. The goal was to test how quickly I can
process compressed text data (i.e read and uncompress on the fly) when running on a single VM and reading directly from cloud storage. The results were quite surprising.&lt;/p></description></item><item><title>Gaia Mapreduce Tutorial - part1</title><link>https://romange.github.io/blog/preview/2019/07/15/gaia-mapreduce-tutorial-part1/</link><pubDate>Mon, 15 Jul 2019 00:00:35 +0300</pubDate><guid>https://romange.github.io/blog/preview/2019/07/15/gaia-mapreduce-tutorial-part1/</guid><description>&lt;p>There are many Java-based mapreduce frameworks that exist today -
Apache &lt;a href="https://beam.apache.org/">Beam&lt;/a>, &lt;a href="https://flink.apache.org/">Flink&lt;/a>, &lt;a href="https://apex.apache.org/">Apex&lt;/a> are to name few.&lt;/p>
&lt;p>&lt;a href="https://github.com/romange/gaia">GAIA-MR&lt;/a> is my attempt to show advantages of a C++ over other languages in this domain.
It&amp;rsquo;s currently implemented for a single machine but even with this restriction I&amp;rsquo;ve seen
up-to 3-7 times reduction in cost and running time vs current alternatives.&lt;/p>
&lt;p>Please note that the single machine restriction put a hard limit on how much data we can process, nethertheless GAIA-MR shines with small-to-medium size workloads (~1TB). This part gives an introduction about mapreduce in general.&lt;/p></description></item><item><title>Introduction to fibers in c++</title><link>https://romange.github.io/blog/preview/2018/12/15/introduction-to-fibers-in-c-/</link><pubDate>Sat, 15 Dec 2018 11:59:52 +0300</pubDate><guid>https://romange.github.io/blog/preview/2018/12/15/introduction-to-fibers-in-c-/</guid><description>In my post about Seastar we&amp;rsquo;ve covered continuations style asynchronous programming. My personal opinion is that this style is hard to work with in C++. In this post I would like to cover alternative, Fiber-based approach. I will use Boost.Fibers library in all my examples.
Fibers, or green threads, or cooperative threads are similar to regular threads but with few important distinctions:
Fibers can not move between system threads and they are usually pinned to a specific thread.</description></item><item><title>Seastar - Asynchronous C++ framework</title><link>https://romange.github.io/blog/preview/2018/07/12/seastar-asynchronous-c-framework/</link><pubDate>Thu, 12 Jul 2018 20:45:24 +0300</pubDate><guid>https://romange.github.io/blog/preview/2018/07/12/seastar-asynchronous-c-framework/</guid><description>&lt;p>Lately, there are many discussions in the programming community in general and in c++ community in particular on how to write efficient asynchronous code. Many concepts like futures, continuations, coroutines are being discussed by c++ standard
committee but not much progress was made besides very minimal support of C++11 futures.&lt;/p>
&lt;p>On the other hand, many mainstream programming languages progressed quicker and adopted asynchronous models
either into a core language or popularized it via standard libraries.
For example, Python (yield) and Lua use coroutines to achieve asynchronisity, java uses continuations and futures, golang and Erlang use green threads, and C and Javascript use callback based actor models.
However, C++ historically lacked the official support for asynchronous programming, which forced
the community to introduce ad-hoc frameworks and libraries that provided this functionality.&lt;/p>
&lt;p>I would like to share my opinion on what I think will be the best direction for asynchronous models in C++ by reviewing two
prominent frameworks: &lt;a href="http://seastar.io/">Seastar&lt;/a> and &lt;a href="https://boost.org/doc/libs/1_67_0/libs/fiber/doc/html/index.html">Boost.Fiber&lt;/a>. This (opinionated) post reviews Seastar.&lt;/p></description></item><item><title>Implementing cheap and precise clock</title><link>https://romange.github.io/blog/preview/2017/11/02/implementing-cheap-and-precise-clock/</link><pubDate>Thu, 02 Nov 2017 13:37:51 +0200</pubDate><guid>https://romange.github.io/blog/preview/2017/11/02/implementing-cheap-and-precise-clock/</guid><description>&lt;p>The posix API for querying high-precision hardware clocks is &lt;code>clock_gettime&lt;/code>. If one second precision is fine then &lt;code>time(nullptr)&lt;/code> is your friend. Unfortunately, using precice clocks takes its price - they are more expensive CPU-wise.&lt;/p></description></item><item><title>Reloading data structures under high throughput</title><link>https://romange.github.io/blog/preview/2017/09/29/reloading-data-structures-under-high-throughput/</link><pubDate>Fri, 29 Sep 2017 15:46:55 +0300</pubDate><guid>https://romange.github.io/blog/preview/2017/09/29/reloading-data-structures-under-high-throughput/</guid><description>&lt;p>Suppose you have a multi-threaded server that serves tens of thousands read queries per second. Those queries use a shared data-structure or index that is mostly immutable during the server run with the exception of periodic index reloads. How do you implement data reloads in that server while keeping it live and kicking in production?&lt;/p></description></item><item><title>How to serialize integers into memory</title><link>https://romange.github.io/blog/preview/2017/09/26/how-to-serialize-integers-into-memory/</link><pubDate>Tue, 26 Sep 2017 22:46:30 +0300</pubDate><guid>https://romange.github.io/blog/preview/2017/09/26/how-to-serialize-integers-into-memory/</guid><description>&lt;p>Here is the analysis of a recent bug I&amp;rsquo;ve stumbled upon. My initial reaction was that
the problem is in the compiler (or that &lt;a href="https://www.youtube.com/watch?v=PIuE5J9dfAo">&amp;ldquo;These are wrong bees&amp;rdquo;&lt;/a>). Consider the code below. We copy 64 integers into a properly allocated destination buffer and yet, if compiled with &lt;code>-O3&lt;/code> switch this code crashes with segfault!&lt;/p></description></item><item><title>My first post</title><link>https://romange.github.io/blog/preview/2017/09/26/my-first-post/</link><pubDate>Tue, 26 Sep 2017 16:16:40 +0300</pubDate><guid>https://romange.github.io/blog/preview/2017/09/26/my-first-post/</guid><description>&lt;p>Hi it&amp;rsquo;s my first attemp at blogging. I&amp;rsquo;ve chosen &lt;a href="https://gohugo.io/">Hugo&lt;/a> with
&lt;a href="https://github.com/digitalcraftsman/hugo-icarus-theme">Icarus theme&lt;/a> for the content generation.
This blog is going to be published vi my &lt;a href="https://github.com/romange/blog">github repository&lt;/a>.
Stay tuned!&lt;/p></description></item></channel></rss>