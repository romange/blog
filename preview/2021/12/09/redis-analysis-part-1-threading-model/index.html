<!doctype html><html lang=en-us><head><title>Redis Analysis - Part 1: Threading model &#183; These are the wrong sort of bees</title><meta name=generator content="Hugo 0.100.2"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=author content="Roman Gershman"><meta name=description content="The wrong sort of bees"><link rel=canonical href=https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/><link rel=icon href=https://romange.github.io/blog/preview/favicon.ico><link rel=apple-touch-icon href=https://romange.github.io/blog/preview/apple-touch-icon.png><link rel=stylesheet href=https://romange.github.io/blog/preview/css/style.css><link rel=stylesheet href=https://romange.github.io/blog/preview/css/font-awesome.min.css><link rel=stylesheet href=https://romange.github.io/blog/preview/css/monokai.css><link rel=stylesheet href=https://romange.github.io/blog/preview/fancybox/jquery.fancybox.css><link href='https://fonts.googleapis.com/css?family=Open+Sans:400italic,400,600' rel=stylesheet type=text/css><link href='https://fonts.googleapis.com/css?family=Source+Code+Pro' rel=stylesheet type=text/css><meta property="og:title" content="Redis Analysis - Part 1: Threading model"><meta property="og:description" content="Following my previous post, we are going start with the &ldquo;hottest potato&rdquo; - single-threaded vs
multi-threaded argument."><meta property="og:type" content="article"><meta property="og:url" content="https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-12-09T11:00:00+03:00"><meta property="article:modified_time" content="2021-12-09T11:00:00+03:00"><meta itemprop=name content="Redis Analysis - Part 1: Threading model"><meta itemprop=description content="Following my previous post, we are going start with the &ldquo;hottest potato&rdquo; - single-threaded vs
multi-threaded argument."><meta itemprop=datePublished content="2021-12-09T11:00:00+03:00"><meta itemprop=dateModified content="2021-12-09T11:00:00+03:00"><meta itemprop=wordCount content="2271"><meta itemprop=keywords content="redis,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Redis Analysis - Part 1: Threading model"><meta name=twitter:description content="Following my previous post, we are going start with the &ldquo;hottest potato&rdquo; - single-threaded vs
multi-threaded argument."><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js></script></head><body><div class=container><div id=container><header id=header><div id=header-main class=header-inner><div class=outer><a href=https://romange.github.io/blog/preview/ id=logo><i class=logo style=background-image:url(https://romange.github.io/blog/preview/css/images/7.png)></i>
<span class=site-title>These are the wrong sort of bees</span></a><nav id=main-nav><a class=main-nav-link href=https://romange.github.io/blog/preview/tags/>Tags</a>
<a class=main-nav-link href=https://romange.github.io/blog/preview/about/>About</a></nav><nav id=sub-nav><div class=profile id=profile-nav><a id=profile-anchor href=javascript:;><img class=avatar src=https://romange.github.io/blog/preview/css/images/avatar.png><i class="fa fa-caret-down"></i></a></div></nav><div id=search-form-wrap><form action=//google.com/search method=get accept-charset=utf-8 class=search-form><input type=search name=q class=search-form-input placeholder=Search>
<button type=submit class=search-form-submit></button>
<input type=hidden name=sitesearch value=https://romange.github.io/blog/preview/></form></div></div></div><div id=main-nav-mobile class="header-sub header-inner"><table class="menu outer"><tbody><tr><td><a class=main-nav-link href=https://romange.github.io/blog/preview/tags/>Tags</a></td><td><a class=main-nav-link href=https://romange.github.io/blog/preview/about/>About</a></td><td><form action=//google.com/search method=get accept-charset=utf-8 class=search-form><input type=search name=q class=search-form-input placeholder=Search>
<input type=hidden name=sitesearch value=https://romange.github.io/blog/preview/></form></td></tr></tbody></table></div></header><div class=outer><aside id=profile><div class="inner profile-inner"><div class="base-info profile-block"><img id=avatar src="https://www.gravatar.com/avatar/4a203a48eb1cdb1b8c47d008f0c139c9?s=100&d=identicon"><h2 id=name>Roman Gershman</h2><h3 id=title>Software Engineer</h3><span id=location><i class="fa fa-map-marker"></i>Tel Aviv</span>
<a id=follow href=https://github.com/romange>Follow</a></div><div class="article-info profile-block"><div class=article-info-block>14
<span>Posts</span></div><div class=article-info-block>17
<span>Tags</span></div></div><div class="profile-block social-links"><table><tr><td><a href=//github.com/romange target=_blank title=GitHub><i class="fa fa-github"></i></a></td><td><a href=//linkedin.com/in/romange target=_blank title=LinkedIn><i class="fa fa-linkedin"></i></a></td><td><a href=//stackoverflow.com/users/romange target=_blank title="Stack Overflow"><i class="fa fa-stack-overflow"></i></a></td><td><a href=https://romange.github.io/blog/preview/index.xml target=_blank title=RSS><i class="fa fa-rss"></i></a></td></tr></table></div></div></aside><section id=main><article id=page-undefined class="article article-type-page" itemscope itemprop=blogPost><div class=article-inner><img src=https://romange.github.io/blog/preview/banners/jet.jpg class=article-banner><header class=article-header><a href=https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/><h1 class=article-title itemprop=name>Redis Analysis - Part 1: Threading model</h1></a><div class=article-meta><div class=article-date><i class="fa fa-calendar"></i>
<time datetime="2021-12-09 11:00:00 +0300 +0300" itemprop=datePublished>Dec 9nd 2021</time>
&#183;
2271
words
&#183;
11
minute read</div><div class=article-category><i class="fa fa-tags"></i>
<a class=article-category-link href=https://romange.github.io/blog/preview/tags/redis>redis</a></div></div></header><div class=article-entry itemprop=articleBody><p>Following my previous post, we are going start with the &ldquo;hottest potato&rdquo; - single-threaded vs
multi-threaded argument.</p><p>This question in the context of Redis has been raised quite a few times before, sometimes sparkling
pretty heated discussions. See, for example<blockquote class=twitter-tweet><p lang=en dir=ltr>I was blocked and riduclued for saying Redis should be multi-threaded. Both by the community and the maker for years.<br><br>Ahem.<a href=https://t.co/Aom4CIYSaf>https://t.co/Aom4CIYSaf</a><br><br>But we already knew this would be the result, didn’t we? This is how modern computers work. It’s not really a debate.</p>&mdash; Kelly Sommers (@kellabyte) <a href="https://twitter.com/kellabyte/status/1111380252398280704?ref_src=twsrc%5Etfw">March 28, 2019</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script>
and <img src=/img/redis-twitter.png alt=replies>.</p><p>Eventually, Salvatore has decided to allow the offloading of I/O processing onto additional threads.
But as I said before, only a single designated thread handles the main Redis dictionary.</p><p>It seems, however, that was not enough for the community. Two and half years ago,
a couple of talented folks from Canada decided to change the status quo and
created a multi-threaded Redis fork called <em>KeyDb</em>.
KeyDb allows multiple threads to access the Redis dictionary by protecting it with spinlocks.
See their <a href=https://medium.com/@john_63123/redis-should-be-multi-threaded-e28319cab744>introductionary post</a>
about this.</p><p>In the previous post I mentioned the following arguments why Redis was built as single-threaded:</p><ol><li>It preserves low tail latency by avoiding contention on locks.</li><li>Redis Cluster provides horizontal scale, which should be as good
as vertical scale if not better: N single-core machines are equivalent to a single process spanning N cores.</li><li>Pipelining gives you more throughput. A redis client can pipeline requests reaching ~1M qps,
which is an order of magnitude higher than the regular traffic throughput.</li><li>Room for the upside on a single machine is limited anyway.</li><li>Single-threaded is simple, multi-threaded is complicated.</li></ol><p>I think there are great benefits of having multi-threaded databases, and I will try to
challenge these arguments. But before we continue forward, let&rsquo;s agree on a few terms:</p><p><em>A vertically scalable system</em> is a system that can scale <em>almost</em> linearly with its performance metrics
(aka requests per second) as a function of available CPUs on a single server.
<em>Horizontally scalable system</em> is a distributed system that can run on multiple nodes/processes
and scale <em>almost</em> linearly with a number of nodes.</p><p>I assert the following claims:</p><ol><li>A vertically scalable system is more cost-efficient than its equivalent horizontally
scalable configuration until it reaches its physical limits on a single server.</li><li>In order to reach the full potential of the modern hardware, and preserve
the low latency property, a system should be designed as a shared-nothing architecture, i.e. avoid
locking and contention, along with the original philosophy of Redis.</li></ol><p>I will try to prove (1). I base (2) on the empirical evidence gathered in the
research community and on lessons learned from other well-designed systems like <a href=https://www.scylladb.com/product/technology/shard-per-core-architecture/>ScyllaDb</a> or <a href=http://twitter.github.io/pelikan/2016/separation-concerns.html>Twitter&rsquo;s Pelikan</a>.</p><h2 id=vertical-scale-vs-horizontal-scale>Vertical scale vs Horizontal scale</h2><p>Imagine you are in the business of selling sugar.
You need to choose between renting a warehouse that can hold 10,000kg of sugar vs 10 warehouses
that can hold 1000kg each. The price of smaller warehouses is precisely a tenth of the bigger one.
It seems that there is no difference, right? However, if you choose to rent 10 smaller warehouses,
you will see that after some time, some, but not all of them, will be nearly empty, and you need to send trucks to fill them up. Why? Because the randomness of nature dictates that
you have almost zero chance that all warehouses are depleted at precisely the same rate.
So you need to spend resources to fill some of the warehouses. Then you will spend resources to fill others and so on. Moreover, you need to staff those warehouses: you might need 2.5 people
per place on average, but you will need to round it up and hire 3 folks in every place.
There will be high-pressure days when your workers will work like crazy,
while during other days, they will do nothing. Let&rsquo;s do some math to understand how to model those inefficiencies.</p><p>Let&rsquo;s assume that $X_1&mldr;X_n$ are independent random variables. Then the expected mean and variance
of their sum is the sum of their means and variances:</p><p>$$ \mathbb{E} \biggl[ \sum_{i=1}^n X_i \biggr] = \sum_{i=1}^n {E[X_i]}$$
$$ Var \biggl[ \sum_{i=1}^n X_i \biggr] = \sum_{i=1}^n {Var[X_i]} $$</p><p>These formulas are basic rules in probability theory, see <a href=https://en.wikipedia.org/wiki/Algebra_of_random_variables>here</a>, for example. Specifically, for independent random variables with
the same mean $\mu$ and standard deviation $\sigma$, we get:</p><p>$$ \mathbb{E} \biggl[ \sum_{i=1}^n X_i \biggr] = \sum_{i=1}^n {E[X_i]} = \sum_{i=1}^n \mu = n* \mu $$</p><p>$$ Var \biggl[ \sum_{i=1}^n X_i \biggr] = \sum_{i=1}^n {Var[X_i]} = \sum_{i=1}^n \sigma^2 = n*\sigma^2 $$</p><p>The last equation can be rewritten as $ StdDev \biggl[\sum_{i=1}^n X_i \biggr] = \sqrt n * \sigma $.</p><p>These equations prove the so-called <code>square root staffing law</code> in queueing theory, which
explains why provisioning a bigger system is more efficient than provisioning a few smaller ones
with equivalent capacity.</p><p>Indeed, when we provision a system that handles the load distributed as $(\mu, \sigma)$,
we usually take an additional margin, say, twice the standard deviation, to cope with
the intrinsic stochastic variability of that load. With $n$ warehouses, we can model
their load as $n$ independent variables distributing as $(\mu, \sigma)$,
therefore, in order to cope with $n * \mu$ effective load,
we will need to staff $2 n \sigma$ additional resources.
However, a single warehouse that handles the load $(n \mu, \sqrt n \sigma)$ needs
only $2 \sqrt n \sigma$ resources to cover the same margin. The bigger warehouse is, the larger
the difference between $\sqrt n \sigma$ and $n \sigma$.</p><p>There are quite a few articles on the internet and lots of academic research in this area.
See <a href=https://www.networkpages.nl/the-golden-rule-of-staffing-in-contact-centers/>this post</a>, for example.</p><p>Obviously, the vertical scale is equivalent to renting a bigger warehouse, and the horizontal scale is
equivalent to provisioning multiple smaller places.</p><p>Let&rsquo;s switch back to the memory-store example. Suppose we provision 9 nodes that are expected to
host 12GB of data <em>on average</em> with the standard deviation - 2GB. We would take servers with
<code>12GB+2*2GB=16GB</code> capacity, in total <code>144GB</code> with <code>36GB</code> margin. With a single server,
however, we would need <code>108 + sqrt(9) * 4 = 120GB</code>. We just reduced the overall cost of the system
by 17%. And if 17% seems not much, we can compare a single server with arbitrary many <code>n</code> servers
of $\frac 1 n$ capacity. With <code>n</code> large enough, the standard deviation becomes the significant
factor compared to the average load. For example, 108 nodes that host 108GB overall, would
need to sustain load $L(\mu=1, \sigma=0.577)$, thus we would need to provision <code>108*(1 + 2*0.577) = 232GB</code>
which is 93% higher than the single server cost.</p><p>So far, I have talked about economy of scale and why pooling resources is more efficient than employing
multiple independent capacities. There are additional factors that increase the total cost of ownership
for multi-node system: I believe that any experienced devop would agree that managing a fleet of <code>N</code> servers
is more complicated than managing a single server just because of moving parts: The chance that at least one of the servers will fail is approximately <code>N</code> time bigger than for a single machine.
In addition, the horizontally scalable system might impose additional restrictions on how the system is used. Specifically, with Redis - Redis Cluster does not allow transactions or multi-key operations covering
multiple nodes, it lacks multi-database support, and it can not issue consistent management operations
like <code>flushdb</code>, <code>save</code> across the cluster.</p><p>The goal of this section is not to persuade you that vertical scale is strictly better than horizontal scale -
obviously, the vertical scale is bounded by the physical limits of its host and can not always be chosen.
However, when there is a choice - it can be the much simpler and most cost-efficient alternative to splitting
your workloads across separate nodes.</p><h2 id=shared-nothing-architecture>Shared-nothing architecture</h2><p><code>“Hardware on which modern workloads must run is remarkably different from the hardware on which current programming paradigms depend, and for which current software infrastructure is designed.”</code> - From Scylla blog.</p><p>Share-nothing architecture is a methodology to build a system in such way that its state is partitioned
among multiple processors, and each processor can execute its work independently
from others. Some prominent examples of shared-nothing architecture:
a) Map-Reduce is a distributed processing framework that processes huge amounts of data over multiple independent workers.
b) Redis Cluster is comprised of independent Redis nodes, where each one of them can perform without relying on others.
c) ScyllaDb is a Cassandra clone that partitions its server database over CPUs in such a way that each CPU
thread consistently handles the same partition. See more info about their <a href=http://seastar.io/shared-nothing/>open-sourced Seastar framework</a>
d) Similarly, Envoy is a prominent proxy server that <a href=https://blog.envoyproxy.io/envoy-threading-model-a8d44b922310>uses thread-local storage</a> to minimize contention between multiple threads inside its process.</p><p>Shared-nothing architecture can be designed over multiple nodes like with (a) and (b) or within a single
process like with (c) and (d).</p><p>In our case, I believe that memory store can be designed as a multi-threaded, single-process system
that utilizes the underlying CPUs using shared-nothing architecture. In other words,
every cpu thread will handle its dictionary partition shard. Other threads can not access directly the data-structures they do not own. If a thread needs to write or read from a dictionary managed by another thread,
it achieves it by sending a message to the owner via a dedicated message bus.
This architecture is not novel - it appears a lot in technical papers, and became mainstream
thanks to ScyllaDb design.</p><p>Any mature database needs to perform operations equivalent to Redis <code>flushdb</code>,
<code>save</code>, <code>load</code> etc. It also needs to perform resize or compaction operations periodically.
With the single-threaded architecture, it means that a single CPU is involved in processing all this data
which heavily reduces database resilience. This brings us to another significant benefit for shared-nothing architecture with the thread-per-core threading model, which is often neglected.
Modern servers maintain a bounded ratio of CPU vs memory.
Say, in AWS, <code>r5</code> family has 1:8 ratio, <code>m5</code> family has 1:4. Similarly, in GCP <code>n2</code> family maintains
ratios between 1-8 GB per vcpu. Therefore, with the thread-per-core model, each thread handles
at most <code>K</code> GB of workload, which means that a database stays resilient whether it&rsquo;s 8GB or
860 GB on a single machine.</p><h2 id=benchmarks>Benchmarks</h2><p>This section addresses arguments (3) and (4) from the beginning of the post,
namely how much upside we can bring by employing shared-nothing architecture using modern cloud
servers. For that, I will use a toy redis-like memory store called <a href=https://github.com/romange/midi-redis>midi-redis</a>. <a href=https://github.com/romange/mini-redis>midi-redis</a> is similar to rust tokio <a href=https://github.com/tokio-rs/mini-redis>mini-redis</a> - i.e. it&rsquo;s built to demonstrate the capabilities of the underlying IO library
by implementing a subset of redis/memcached commands.</p><p>Specifically, midi-redis supports <code>GET</code>, <code>SET</code>, <code>PING</code>, and <code>DEBUG POPULATE</code> commands.
It also has complimentary support for memcached <code>GET</code> and <code>SET</code> commands and pipeline mode for both protocols.</p><p>The underlying I/O library that powers <code>midi-redis</code> is <a href=https://github.com/romange/helio>helio</a>
that uses linux io-uring api underneath. <code>helio</code> is specially designed for
shared-nothing architectures and it is the evolution of my previous library <a href=https://github.com/romange/gaia>GAIA</a>.</p><p>I performed benchmarking of <code>midi-redis</code> on a variety of instances on the AWS cloud.
The point is not to evaluate <code>midi-redis</code> but to show the true potential of the hardware vs what
Redis gives us on this hardware. Please, treat these numbers as directional only -
I run each load-test only once, so I believe there is some variance that could affect numbers in +-15% range. <code>redis-1</code> bar in the graph represents Redis 6 with the <code>io-threads=1</code> configuration, and <code>redis-8</code> denotes
<code>io-threads=8</code> configuration. Redis results were similar on all instance types,
therefore I used the <code>redis-1</code> run on <code>c5.18xlarge</code> as my relative baseline for all other runs.</p><p>I used read-only traffic to minimize the influence of memory allocations and
database resizes on the results. Also, I run &ldquo;debug populate 10000000&rdquo; command before each run
to fill a server under test with data. Finally, I run <a href=https://github.com/RedisLabs/memtier_benchmark>memtier_benchmark</a> from 3 client machines in the same zone with the following configuration:
<code>--key-prefix=key: --key-pattern=P:P --ratio 0:1 -n 2000000</code>. The number of threads and connections
for <code>memtier_benchmark</code> were chosen to maximize the throughput of the server under test and were different
for each instance type.</p><p>My first graph shows throughput for regular traffic without pipelined requests:
<img src=/img/throughput-p1.png alt=no-pipeline></p><p>You can see that midi-redis running most network-capable AWS instance c6gn.16xlarge has the throughput
that is >20 times higher than <code>redis-1</code> and >10 times higher than <code>redis-8</code>.</p><p>My next graph shows the throughput of instances with pipeline mode when <code>memtier_benchmark</code> sends bursts
of 10 requests at once (<code>--pipeline 10</code>): <img src=/img/throughput-p10.png alt=pipeline-10>
Here, <code>c6gn.16xlarge</code> has seven times more throughput reaching a staggering 7.4M qps. Interestingly,
<code>redis-8</code> is a bit slower than <code>redis-1</code> because Redis main thread becomes the bottleneck for pipelined traffic.
And <code>redis-8</code> spends additional cpu for coordination with its io-threads. <code>midi-redis</code> on the other hand,
splits its dictionary between all its threads, reduces their communication to a minimum,
and scales its performance much better.</p><p>I do not know if a factor of 20 or a factor of 7 sounds impressive to you, but please remember that
Redis 6 is the product of a decade of development and optimizations. Even 5%, 10% of incremental improvement is significant here. By changing the foundation, we allow potential
2000% upside for the non-pipeline case. Moreover, with time we will benefit from additional
tailwinds from hardware advancements - with better networking and more cpus we will see
even higher rates.</p><p>The speed of a car is 140 km/h, the speed of a jet plane is 950 km/h and the speed of sound is 1235 km/h.
If Redis is a fast car, then we could fly instead on a supersonic plane.</p></div><footer class=article-footer><a data-url=https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/ data-id=e4af4bcd235220dfd2cb775d51d9216f class=article-share-link><i class="fa fa-share"></i>
Share</a>
<a href=https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/#disqus_thread class=article-comment-link>Comments</a>
<script>(function(e){if(typeof __SHARE_BUTTON_BINDED__=='undefined'||!__SHARE_BUTTON_BINDED__)__SHARE_BUTTON_BINDED__=!0;else return;e('body').on('click',function(){e('.article-share-box.on').removeClass('on')}).on('click','.article-share-link',function(c){c.stopPropagation();var t,r,s=e(this),i=s.attr('data-url'),n=encodeURIComponent(i),o='article-share-box-'+s.attr('data-id'),a=s.offset();if(e('#'+o).length){if(t=e('#'+o),t.hasClass('on')){t.removeClass('on');return}}else r=['<div id="'+o+'" class="article-share-box">','<input class="article-share-input" value="'+i+'">','<div class="article-share-links">','<a href="https://twitter.com/intent/tweet?url='+n+'" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>','<a href="https://www.facebook.com/sharer.php?u='+n+'" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>','<a href="http://pinterest.com/pin/create/button/?url='+n+'" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>','<a href="https://plus.google.com/share?url='+n+'" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>','</div>','</div>'].join(''),t=e(r),e('body').append(t);e('.article-share-box.on').hide(),t.css({top:a.top+25,left:a.left}).addClass('on')}).on('click','.article-share-box',function(e){e.stopPropagation()}).on('click','.article-share-box-input',function(){e(this).select()}).on('click','.article-share-box-link',function(e){e.preventDefault(),e.stopPropagation(),window.open(this.href,'article-share-box-window-'+Date.now(),'width=500,height=450')})})(jQuery)</script></footer></div><nav id=article-nav><a href=https://romange.github.io/blog/preview/2021/11/28/a-prelude-to-analysis-of-redis-memory-store/ id=article-nav-older class=article-nav-link-wrap><strong class=article-nav-caption>Older</strong><div class=article-nav-title>A prelude to analysis of Redis memory-store</div></a><a href=https://romange.github.io/blog/preview/2022/01/30/redis-analysis-part-2-simplicity/ id=article-nav-newer class=article-nav-link-wrap><strong class=article-nav-caption>Newer</strong><div class=article-nav-title>Redis Analysis - Part 2: Simplicity</div></a></nav></article><section id=comments><div id=disqus_thread><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var t=document,e=t.createElement('script');e.async=!0,e.src='//romange.disqus.com/embed.js',e.setAttribute('data-timestamp',+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></section></section><aside id=sidebar><div class=widget-wrap><h3 class=widget-title>Recents</h3><div class=widget><ul id=recent-post><li><div class=item-thumbnail><a href=https://romange.github.io/blog/preview/2022/06/14/dragonfly-cache-design/ class=thumbnail><span class="thumbnail-image thumbnail-none"></span></a></div><div class=item-inner><p class=item-title><a href=https://romange.github.io/blog/preview/2022/06/14/dragonfly-cache-design/ class=title>Dragonfly Cache Design</a></p><p class=item-date><time datetime="2022-06-14 09:53:03 +0300 +0300" itemprop=datePublished>Jun 14nd 2022</time></p></div></li><li><div class=item-thumbnail><a href=https://romange.github.io/blog/preview/2022/01/30/redis-analysis-part-2-simplicity/ class=thumbnail><span style=background-image:url(https://romange.github.io/blog/preview/banners/simple.jpg) alt="Redis Analysis - Part 1: Threading model" class=thumbnail-image></span></a></div><div class=item-inner><p class=item-title><a href=https://romange.github.io/blog/preview/2022/01/30/redis-analysis-part-2-simplicity/ class=title>Redis Analysis - Part 2: Simplicity</a></p><p class=item-date><time datetime="2022-01-30 20:00:00 +0200 +0200" itemprop=datePublished>Jan 30nd 2022</time></p></div></li><li><div class=item-thumbnail><a href=https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/ class=thumbnail><span style=background-image:url(https://romange.github.io/blog/preview/banners/jet.jpg) alt="Redis Analysis - Part 1: Threading model" class=thumbnail-image></span></a></div><div class=item-inner><p class=item-title><a href=https://romange.github.io/blog/preview/2021/12/09/redis-analysis-part-1-threading-model/ class=title>Redis Analysis - Part 1: Threading model</a></p><p class=item-date><time datetime="2021-12-09 11:00:00 +0300 +0300" itemprop=datePublished>Dec 9nd 2021</time></p></div></li><li><div class=item-thumbnail><a href=https://romange.github.io/blog/preview/2021/11/28/a-prelude-to-analysis-of-redis-memory-store/ class=thumbnail><span style=background-image:url(https://romange.github.io/blog/preview/banners/1200px-Redis_Logo.svg.png) alt="Redis Analysis - Part 1: Threading model" class=thumbnail-image></span></a></div><div class=item-inner><p class=item-title><a href=https://romange.github.io/blog/preview/2021/11/28/a-prelude-to-analysis-of-redis-memory-store/ class=title>A prelude to analysis of Redis memory-store</a></p><p class=item-date><time datetime="2021-11-28 17:46:19 +0300 +0300" itemprop=datePublished>Nov 28nd 2021</time></p></div></li><li><div class=item-thumbnail><a href=https://romange.github.io/blog/preview/2020/09/05/io_uring-powered-event-loop-with-efficient-message-passing/ class=thumbnail><span class="thumbnail-image thumbnail-none"></span></a></div><div class=item-inner><p class=item-title><a href=https://romange.github.io/blog/preview/2020/09/05/io_uring-powered-event-loop-with-efficient-message-passing/ class=title>IO_URING powered event-loop with efficient message passing</a></p><p class=item-date><time datetime="2020-09-05 20:30:11 +0300 +0300" itemprop=datePublished>Sep 5nd 2020</time></p></div></li></ul></div></div><div class=widget-wrap><h3 class=widget-title>Tags</h3><div class=widget><ul class=category-list><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/asynchronous>asynchronous</a>
<span class=category-list-count>2</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/backend>backend</a>
<span class=category-list-count>2</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/blogging>blogging</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/c++>c++</a>
<span class=category-list-count>8</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/code-generation>code-generation</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/concurrency>concurrency</a>
<span class=category-list-count>2</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/dragonfly>dragonfly</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/fibers>fibers</a>
<span class=category-list-count>2</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/gaia>gaia</a>
<span class=category-list-count>3</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/io_uring>io_uring</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/linux>linux</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/mapreduce>mapreduce</a>
<span class=category-list-count>3</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/posix>posix</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/programming>programming</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/reactive>reactive</a>
<span class=category-list-count>1</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/redis>redis</a>
<span class=category-list-count>4</span></li><li class=category-list-item><a class=category-list-link href=https://romange.github.io/blog/preview/tags/seastar>seastar</a>
<span class=category-list-count>1</span></li></ul></div></div><div class=widget-wrap><h3 class=widget-title>Tag cloud</h3><div class="widget tagcloud"><a href=https://romange.github.io/blog/preview/tags/asynchronous style=font-size:12px>asynchronous</a>
<a href=https://romange.github.io/blog/preview/tags/backend style=font-size:12px>backend</a>
<a href=https://romange.github.io/blog/preview/tags/blogging style=font-size:12px>blogging</a>
<a href=https://romange.github.io/blog/preview/tags/c++ style=font-size:12px>c++</a>
<a href=https://romange.github.io/blog/preview/tags/code-generation style=font-size:12px>code-generation</a>
<a href=https://romange.github.io/blog/preview/tags/concurrency style=font-size:12px>concurrency</a>
<a href=https://romange.github.io/blog/preview/tags/dragonfly style=font-size:12px>dragonfly</a>
<a href=https://romange.github.io/blog/preview/tags/fibers style=font-size:12px>fibers</a>
<a href=https://romange.github.io/blog/preview/tags/gaia style=font-size:12px>gaia</a>
<a href=https://romange.github.io/blog/preview/tags/io_uring style=font-size:12px>io_uring</a>
<a href=https://romange.github.io/blog/preview/tags/linux style=font-size:12px>linux</a>
<a href=https://romange.github.io/blog/preview/tags/mapreduce style=font-size:12px>mapreduce</a>
<a href=https://romange.github.io/blog/preview/tags/posix style=font-size:12px>posix</a>
<a href=https://romange.github.io/blog/preview/tags/programming style=font-size:12px>programming</a>
<a href=https://romange.github.io/blog/preview/tags/reactive style=font-size:12px>reactive</a>
<a href=https://romange.github.io/blog/preview/tags/redis style=font-size:12px>redis</a>
<a href=https://romange.github.io/blog/preview/tags/seastar style=font-size:12px>seastar</a></div></div><div id=toTop class="fa fa-angle-up"></div></aside></div></div><footer id=footer><div class=outer><div id=footer-info class=inner>&copy; 2022
Roman Gershman</div></div></footer><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-107146718-1','auto'),ga('send','pageview'))</script><script src=https://romange.github.io/blog/preview/fancybox/jquery.fancybox.pack.js></script>
<script src=https://romange.github.io/blog/preview/js/script.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>